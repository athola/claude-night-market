"""Tests for post_learnings_to_discussions.py.

Part of Issue #69 Phase 6a: Collective Intelligence Loop
"""

from __future__ import annotations

import json
import sys
from datetime import datetime, timezone
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

# Add scripts to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "scripts"))

from post_learnings_to_discussions import (
    DiscussionConfig,
    LearningSummary,
    PostedRecord,
    check_existing_discussion,
    create_discussion,
    format_discussion_body,
    get_repo_node_id,
    parse_learnings_md,
    post_learnings,
)

# Sample LEARNINGS.md content for testing
SAMPLE_LEARNINGS_MD = """\
# Skill Performance Learnings

**Last Updated**: 2026-02-21 04:30:00 UTC
**Analysis Period**: Last 30 days
**Skills Analyzed**: 15
**Total Executions**: 342

---

## High-Impact Issues

Skills with significant problems requiring immediate attention.

### imbue:proof-of-work
**Type**: high_failure_rate
**Severity**: high
**Metric**: 42.3% success rate
**Detail**: 11/26 failures
**Recent Errors**:
- ValidationError: Missing acceptance_criteria field
- FileNotFoundError: PROOF.md not found

---

## Slow Execution

Skills exceeding 10s average execution time.

| Skill | Avg Duration | Max Duration | Executions |
|-------|--------------|--------------|------------|
| `sanctum:pr-agent` | 45.2s | 120.5s | 18 |
| `pensive:code-reviewer` | 32.1s | 89.3s | 24 |

---

## Low User Ratings

Skills with < 3.5/5.0 average rating from evaluations.

### abstract:skill-auditor - 2.8/5.0
**Common Friction**:
- Too verbose output
- Missing examples

---

*Generated by aggregate_skill_logs.py (Issue #69 Phase 3)*
"""


class TestParseLearningsMd:
    """Feature: Parse LEARNINGS.md into structured data

    As a collective intelligence system
    I want to parse LEARNINGS.md into structured data
    So that I can format it for GitHub Discussions
    """

    @pytest.mark.unit
    def test_extracts_metadata(self) -> None:
        """Scenario: Extract header metadata
        Given a LEARNINGS.md with standard header fields
        When I parse the content
        Then all metadata fields are extracted correctly
        """
        summary = parse_learnings_md(SAMPLE_LEARNINGS_MD)

        assert summary.last_updated == "2026-02-21 04:30:00 UTC"
        assert summary.analysis_period == "Last 30 days"
        assert summary.skills_analyzed == 15
        assert summary.total_executions == 342

    @pytest.mark.unit
    def test_extracts_high_impact_issues(self) -> None:
        """Scenario: Extract high-impact issues
        Given a LEARNINGS.md with high-impact issues section
        When I parse the content
        Then issues are extracted with skill name, type, severity, and metric
        """
        summary = parse_learnings_md(SAMPLE_LEARNINGS_MD)

        assert len(summary.high_impact_issues) == 1
        issue = summary.high_impact_issues[0]
        assert issue["skill"] == "imbue:proof-of-work"
        assert issue["type"] == "high_failure_rate"
        assert issue["severity"] == "high"
        assert issue["metric"] == "42.3% success rate"

    @pytest.mark.unit
    def test_extracts_slow_skills(self) -> None:
        """Scenario: Extract slow execution table
        Given a LEARNINGS.md with slow execution table
        When I parse the content
        Then slow skills are extracted from table rows
        """
        summary = parse_learnings_md(SAMPLE_LEARNINGS_MD)

        assert len(summary.slow_skills) == 2
        assert summary.slow_skills[0]["skill"] == "sanctum:pr-agent"
        assert summary.slow_skills[0]["avg_duration"] == "45.2s"
        assert summary.slow_skills[1]["skill"] == "pensive:code-reviewer"
        assert summary.slow_skills[1]["executions"] == 24

    @pytest.mark.unit
    def test_extracts_low_rated_skills(self) -> None:
        """Scenario: Extract low-rated skills
        Given a LEARNINGS.md with low user ratings section
        When I parse the content
        Then low-rated skills are extracted with name and rating
        """
        summary = parse_learnings_md(SAMPLE_LEARNINGS_MD)

        assert len(summary.low_rated_skills) == 1
        assert summary.low_rated_skills[0]["skill"] == "abstract:skill-auditor"
        assert summary.low_rated_skills[0]["rating"] == 2.8

    @pytest.mark.unit
    def test_handles_empty_content(self) -> None:
        """Scenario: Handle empty LEARNINGS.md
        Given an empty LEARNINGS.md
        When I parse the content
        Then all fields default to empty/zero
        """
        summary = parse_learnings_md("")

        assert summary.skills_analyzed == 0
        assert summary.total_executions == 0
        assert summary.high_impact_issues == []
        assert summary.slow_skills == []
        assert summary.low_rated_skills == []

    @pytest.mark.unit
    def test_handles_header_only_content(self) -> None:
        """Scenario: Handle LEARNINGS.md with only header metadata
        Given a LEARNINGS.md with metadata but no issue sections
        When I parse the content
        Then metadata is extracted and issue lists are empty
        """
        content = """\
# Skill Performance Learnings

**Last Updated**: 2026-02-21 04:30:00 UTC
**Analysis Period**: Last 7 days
**Skills Analyzed**: 3
**Total Executions**: 10
"""
        summary = parse_learnings_md(content)

        assert summary.skills_analyzed == 3
        assert summary.total_executions == 10
        assert summary.high_impact_issues == []


class TestFormatDiscussionBody:
    """Feature: Format parsed learnings into a Discussion post

    As a collective intelligence system
    I want to format learnings as readable markdown
    So that the community can review and react to them
    """

    @pytest.mark.unit
    def test_includes_summary_stats(self) -> None:
        """Scenario: Include summary statistics
        Given a parsed learning summary with stats
        When I format it as a discussion body
        Then the stats section is present with correct values
        """
        summary = LearningSummary(
            analysis_period="Last 30 days",
            skills_analyzed=15,
            total_executions=342,
            last_updated="2026-02-21",
        )
        body = format_discussion_body(summary)

        assert "## Summary Stats" in body
        assert "Skills Analyzed**: 15" in body
        assert "Total Executions**: 342" in body

    @pytest.mark.unit
    def test_includes_high_impact_issues(self) -> None:
        """Scenario: Include top issues section
        Given a summary with high-impact issues
        When I format it as a discussion body
        Then the issues are listed with severity and metrics
        """
        summary = LearningSummary(
            high_impact_issues=[
                {
                    "skill": "test:skill",
                    "severity": "high",
                    "metric": "40% success",
                    "type": "high_failure_rate",
                }
            ],
        )
        body = format_discussion_body(summary)

        assert "## Top Issues" in body
        assert "test:skill" in body
        assert "[high]" in body

    @pytest.mark.unit
    def test_includes_reaction_instructions(self) -> None:
        """Scenario: Include reaction instructions for voting
        Given any learning summary
        When I format it as a discussion body
        Then instructions for fire emoji voting are included
        """
        summary = LearningSummary(skills_analyzed=1, total_executions=5)
        body = format_discussion_body(summary)

        assert "\U0001f525" in body
        assert "3+ reactions" in body

    @pytest.mark.unit
    def test_omits_empty_sections(self) -> None:
        """Scenario: Omit sections with no data
        Given a summary with no slow skills or low-rated skills
        When I format it as a discussion body
        Then those sections are not present
        """
        summary = LearningSummary(
            skills_analyzed=5,
            total_executions=20,
        )
        body = format_discussion_body(summary)

        assert "## Slow Execution" not in body
        assert "## Low-Rated Skills" not in body


class TestDiscussionConfig:
    """Feature: Load opt-out configuration

    As a user
    I want to configure whether learnings are auto-posted
    So that I can opt out of sharing if desired
    """

    @pytest.mark.unit
    def test_defaults_to_enabled(self) -> None:
        """Scenario: Default config enables posting
        Given no config file exists
        When I load the config
        Then auto_post_learnings is True
        """
        config = DiscussionConfig()

        assert config.auto_post_learnings is True
        assert config.target_repo == "athola/claude-night-market"
        assert config.promotion_threshold == 3

    @pytest.mark.unit
    def test_loads_from_file(self, tmp_path: Path) -> None:
        """Scenario: Load config from file
        Given a config.json with auto_post_learnings=false
        When I load the config
        Then the setting is respected
        """
        config_dir = tmp_path / "discussions"
        config_dir.mkdir(parents=True)
        config_file = config_dir / "config.json"
        config_file.write_text(json.dumps({"auto_post_learnings": False}))

        with patch(
            "post_learnings_to_discussions.get_config_dir",
            return_value=config_dir,
        ):
            config = DiscussionConfig.load()

        assert config.auto_post_learnings is False

    @pytest.mark.unit
    def test_handles_malformed_config(self, tmp_path: Path) -> None:
        """Scenario: Handle malformed config file
        Given a config.json with invalid JSON
        When I load the config
        Then defaults are used
        """
        config_dir = tmp_path / "discussions"
        config_dir.mkdir(parents=True)
        (config_dir / "config.json").write_text("{invalid json")

        with patch(
            "post_learnings_to_discussions.get_config_dir",
            return_value=config_dir,
        ):
            config = DiscussionConfig.load()

        assert config.auto_post_learnings is True


class TestPostedRecord:
    """Feature: Track posted discussions for deduplication

    As a collective intelligence system
    I want to track which discussions have been posted
    So that I don't create duplicates
    """

    @pytest.mark.unit
    def test_empty_record_has_no_posts(self) -> None:
        """Scenario: New record has no posts
        Given a fresh PostedRecord
        When I check any title
        Then it reports as not posted
        """
        record = PostedRecord()
        assert not record.is_posted("[Learning] 2026-02-21")

    @pytest.mark.unit
    def test_tracks_posted_titles(self) -> None:
        """Scenario: Track a posted discussion
        Given a PostedRecord with a recorded post
        When I check that title
        Then it reports as already posted
        """
        record = PostedRecord(
            posted={"[Learning] 2026-02-21": "https://example.com/discussion/1"}
        )
        assert record.is_posted("[Learning] 2026-02-21")
        assert not record.is_posted("[Learning] 2026-02-22")

    @pytest.mark.unit
    def test_save_and_load_roundtrip(self, tmp_path: Path) -> None:
        """Scenario: Save and reload posted record
        Given a PostedRecord with data
        When I save and reload it
        Then the data is preserved
        """
        config_dir = tmp_path / "discussions"
        config_dir.mkdir(parents=True)

        record = PostedRecord(
            posted={"[Learning] 2026-02-21": "https://example.com/d/1"},
            repo_node_id="R_abc123",
        )

        with patch(
            "post_learnings_to_discussions.get_config_dir",
            return_value=config_dir,
        ):
            record.save()
            loaded = PostedRecord.load()

        assert loaded.posted == record.posted
        assert loaded.repo_node_id == "R_abc123"


class TestRunGhGraphql:
    """Feature: Execute GraphQL queries via gh CLI

    As a collective intelligence system
    I want to run GraphQL queries via the gh CLI
    So that I can interact with GitHub Discussions API
    """

    @pytest.mark.unit
    def test_get_repo_node_id_uses_cache(self) -> None:
        """Scenario: Use cached repo node ID
        Given a PostedRecord with a cached repo_node_id
        When I request the repo node ID
        Then the cache is used without calling gh
        """
        record = PostedRecord(repo_node_id="R_cached123")
        result = get_repo_node_id(record)
        assert result == "R_cached123"

    @pytest.mark.unit
    @patch("post_learnings_to_discussions.run_gh_graphql")
    def test_get_repo_node_id_fetches_and_caches(self, mock_graphql: MagicMock) -> None:
        """Scenario: Fetch and cache repo node ID
        Given a PostedRecord with no cached ID
        When I request the repo node ID
        Then gh is called and the result is cached
        """
        mock_graphql.return_value = {"data": {"repository": {"id": "R_new456"}}}
        record = PostedRecord()
        record.save = MagicMock()  # Don't write to disk

        result = get_repo_node_id(record)

        assert result == "R_new456"
        assert record.repo_node_id == "R_new456"
        record.save.assert_called_once()

    @pytest.mark.unit
    @patch("post_learnings_to_discussions.run_gh_graphql")
    def test_check_existing_discussion_found(self, mock_graphql: MagicMock) -> None:
        """Scenario: Find existing discussion by title
        Given a discussion with title "[Learning] 2026-02-21" exists
        When I check for that title
        Then the discussion URL is returned
        """
        mock_graphql.return_value = {
            "data": {
                "search": {
                    "nodes": [
                        {
                            "title": "[Learning] 2026-02-21",
                            "url": "https://github.com/athola/claude-night-market/discussions/42",
                        }
                    ]
                }
            }
        }
        url = check_existing_discussion("[Learning] 2026-02-21")
        assert url == "https://github.com/athola/claude-night-market/discussions/42"

    @pytest.mark.unit
    @patch("post_learnings_to_discussions.run_gh_graphql")
    def test_check_existing_discussion_not_found(self, mock_graphql: MagicMock) -> None:
        """Scenario: No existing discussion found
        Given no discussion with the searched title exists
        When I check for that title
        Then None is returned
        """
        mock_graphql.return_value = {"data": {"search": {"nodes": []}}}
        url = check_existing_discussion("[Learning] 2026-02-21")
        assert url is None

    @pytest.mark.unit
    @patch("post_learnings_to_discussions.run_gh_graphql")
    def test_create_discussion_returns_url(self, mock_graphql: MagicMock) -> None:
        """Scenario: Create a new discussion
        Given valid repo ID, category ID, title, and body
        When I create a discussion
        Then the created discussion URL is returned
        """
        mock_graphql.return_value = {
            "data": {
                "createDiscussion": {
                    "discussion": {
                        "url": "https://github.com/athola/claude-night-market/discussions/99"
                    }
                }
            }
        }
        url = create_discussion("R_abc", "DIC_xyz", "Test Title", "Test Body")
        assert "discussions/99" in url


class TestPostLearnings:
    """Feature: End-to-end posting workflow

    As a collective intelligence system
    I want to parse LEARNINGS.md and post to Discussions
    So that learnings are shared with the community
    """

    @pytest.mark.unit
    def test_skips_when_disabled(self) -> None:
        """Scenario: Respect opt-out config
        Given auto_post_learnings is False in config
        When I run post_learnings
        Then no posting occurs and None is returned
        """
        with patch(
            "post_learnings_to_discussions.DiscussionConfig.load",
            return_value=DiscussionConfig(auto_post_learnings=False),
        ):
            result = post_learnings()
        assert result is None

    @pytest.mark.unit
    def test_skips_when_no_learnings_file(self, tmp_path: Path) -> None:
        """Scenario: No LEARNINGS.md file
        Given LEARNINGS.md does not exist
        When I run post_learnings
        Then None is returned with a warning
        """
        result = post_learnings(learnings_path=tmp_path / "nonexistent.md")
        assert result is None

    @pytest.mark.unit
    def test_skips_when_empty_learnings(self, tmp_path: Path) -> None:
        """Scenario: Empty LEARNINGS.md
        Given LEARNINGS.md exists but is empty
        When I run post_learnings
        Then None is returned
        """
        empty_file = tmp_path / "LEARNINGS.md"
        empty_file.write_text("")
        result = post_learnings(learnings_path=empty_file)
        assert result is None

    @pytest.mark.unit
    def test_skips_when_already_posted_today(self, tmp_path: Path) -> None:
        """Scenario: Already posted today
        Given today's learning was already posted
        When I run post_learnings
        Then the existing URL is returned without creating a new discussion
        """
        learnings_file = tmp_path / "LEARNINGS.md"
        learnings_file.write_text(SAMPLE_LEARNINGS_MD)

        today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        existing_url = "https://github.com/athola/claude-night-market/discussions/42"

        with (
            patch(
                "post_learnings_to_discussions.DiscussionConfig.load",
                return_value=DiscussionConfig(),
            ),
            patch(
                "post_learnings_to_discussions.PostedRecord.load",
                return_value=PostedRecord(posted={f"[Learning] {today}": existing_url}),
            ),
        ):
            result = post_learnings(learnings_path=learnings_file)

        assert result == existing_url

    @pytest.mark.unit
    @patch("post_learnings_to_discussions.create_discussion")
    @patch("post_learnings_to_discussions.check_existing_discussion")
    @patch("post_learnings_to_discussions.get_repo_node_id")
    def test_posts_new_discussion(
        self,
        mock_repo_id: MagicMock,
        mock_check: MagicMock,
        mock_create: MagicMock,
        tmp_path: Path,
    ) -> None:
        """Scenario: Post a new learning discussion
        Given LEARNINGS.md exists with valid content and no prior post today
        When I run post_learnings
        Then a new discussion is created and the URL is returned
        """
        learnings_file = tmp_path / "LEARNINGS.md"
        learnings_file.write_text(SAMPLE_LEARNINGS_MD)

        mock_repo_id.return_value = "R_test123"
        mock_check.return_value = None
        new_url = "https://github.com/athola/claude-night-market/discussions/100"
        mock_create.return_value = new_url

        record = PostedRecord()
        record.save = MagicMock()

        with (
            patch(
                "post_learnings_to_discussions.DiscussionConfig.load",
                return_value=DiscussionConfig(),
            ),
            patch(
                "post_learnings_to_discussions.PostedRecord.load",
                return_value=record,
            ),
        ):
            result = post_learnings(learnings_path=learnings_file)

        assert result == new_url
        mock_create.assert_called_once()
        record.save.assert_called()
